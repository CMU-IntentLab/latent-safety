act: SiLU
actType: Tanh
action_repeat: 1
actor: {dist: normal, entropy: 0.0003, eps: 1e-05, grad_clip: 100.0, layers: 2, lr: 3e-05,
  max_std: 1.0, min_std: 0.1, outscale: 1.0, std: learned, temp: 0.1, unimix_ratio: 0.01}
actor_only_scale: 0.0
annealing: null
architecture: [100, 100]
augment_images: false
batch_length: 32
batch_size: 32
bc_loss_only: false
bc_reg: true
bc_reg_wd: 1.0
bc_reg_weight: 1.0
checkPeriod: 10000
compile: true
consRadius: 0.5
cont_ensemble_size: 1
cont_ensemble_subsample: 1
cont_head: {layers: 2, loss_scale: 1.0, outscale: 1.0}
costType: sparse
critic: {dist: symlog_disc, eps: 1e-05, grad_clip: 100.0, layers: 2, lr: 3e-05, outscale: 0.0,
  slow_target: true, slow_target_fraction: 0.02, slow_target_update: 1}
critic_ensemble_size: 1
critic_ensemble_subsample: 2
critic_reset_every: 0
dataset_size: 1000000
debug: false
decay_model_lr: false
decoder: {act: SiLU, cnn_depth: 32, cnn_keys: image, cnn_sigmoid: false, image_dist: mse,
  kernel_size: 4, minres: 4, mlp_keys: '', mlp_layers: 5, mlp_units: 1024, norm: true,
  outscale: 1.0, vector_dist: symlog_mse}
deterministic_run: true
device: cuda:0
disag_action_cond: false
disag_layers: 4
disag_log: true
disag_models: 10
disag_offset: 1
disag_target: stoch
disag_units: 400
discount: 0.997
discount_lambda: 0.95
doneType: toEnd
done_mode: 1
dropout_recur_in_residuals: false
dropout_recurrent_prob: 0
dt: 0.05
dyn_deter: 512
dyn_discrete: 0
dyn_hidden: 512
dyn_mean_act: none
dyn_min_std: 0.1
dyn_rec_depth: 1
dyn_scale: 0.5
dyn_std_act: sigmoid2
dyn_stoch: 32
ema_decay: 0.999
ema_power: 0.8
encoder: {act: SiLU, cnn_depth: 32, cnn_keys: image, kernel_size: 4, minres: 4, mlp_keys: '',
  mlp_layers: 5, mlp_units: 1024, norm: true, symlog_inputs: true}
ensemble_residuals: false
envs: 1
eval_every: 500
eval_num_seeds: 50
eval_per_seed: 1
eval_state_mean: false
evaldir: null
exp_name: ''
expl_behavior: greedy
expl_extr_scale: 0.0
expl_intr_scale: 1.0
expl_until: 0
freeze_encoder: true
from_ckpt: null
from_prefill_dir: null
gamma: 0.9999
grad_clip: 1000
grad_heads: [decoder, reward, cont]
grayscale: false
grid_path: /home/kensuke/latent-safety/logs/grid/LS_BRT_v1_w1.25.npy
gt_lx: false
hybrid_critic_fitting: false
hybrid_training: true
ignore_base_policy: false
imag_gradient: dynamics
imag_gradient_mix: 0.0
imag_horizon: 15
image: null
image_size: 64
initial: learned
initial_joint_train_steps: 0
kl_free: 1.0
learnedDyn: null
learnedMargin: null
learningRate: 0.001
log_every: 50
log_every_video: 500
logdir: logs/dreamer_cont/0922/030257
lx_ckpt: null
mask_recur: false
maxUpdates: 400000
memoryCapacity: 10000
mode: RA
model_lr: 0.0001
model_only_scale: 0.0
multi_task_data: false
name: world_model_new
no_joint_steps: false
norm: true
numT: 25
num_actions: 3
num_exp_trajs: 1900
num_pts: 5000
nx: 51
ny: 51
nz: 51
obs_lr: 0.001
obs_r: 0.5
obs_step: 1
obs_x: 0
obs_y: 0
offline_evaldir: ''
offline_traindir: ''
opt: adam
opt_eps: 1e-08
outFolder: logs/experiments
parallel: false
plotFigure: null
precision: 32
prefill: 5000
pretrain: 100
pretrain_actor_steps: 0
pretrain_annealing: null
pretrain_bc_loss_only: true
pretrain_ema: false
pretrain_joint_steps: 40000
pretrain_loss: ce
pretrain_on_random: false
pretrain_on_random_mixed: false
pretrain_reward_val: null
pretrain_separately: false
randomSeed: 0
recon_pretrain: true
rep_scale: 0.1
reset_every: 0
residual_discount: 0.95
residual_init_zeros: false
reward_EMA: true
reward_ensemble_size: 1
reward_ensemble_subsample: 1
reward_head: {dist: symlog_disc, layers: 2, loss_scale: 1.0, outscale: 0.0}
seed: 0
seed_in_batches: true
separate_reward_training: true
shape_rewards: true
shift_rewards: false
showTime: null
size: [128, 128]
speed: 1
steps: 1000000.0
steps_per_batch: 100
storeFigure: true
targetRadius: 0.5
task: dubins
terminalType: g
time_limit: 100
train_ratio: 1024
train_residuals: true
traindir: null
turnRadius: 0.8
u_max: 1.25
unimix_ratio: 0.01
units: 512
updateTimes: 20
utd_ratio: 1
validation_mse_trajs: 50
video_pred_log: true
warmup: true
warmupIter: 500
weight_decay: 0.0
wm: true
x_max: 1.1
x_min: -1.1
y_max: 1.1
y_min: -1.1
